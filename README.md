# Credit Card Fraud Detection Project

This project develops a **machine learning model** to detect fraudulent credit card transactions and presents it as an **interactive Streamlit web application**.

The model is trained on the [Kaggle Credit Card Fraud Detection Dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud).  
Because the dataset is **highly imbalanced**, the training process uses **SMOTE (Synthetic Minority Over-sampling Technique)** to create a more balanced training set.

Additionally, **SHAP (SHapley Additive exPlanations)** has been integrated for **deep model interpretability**, making this a **portfolio-ready data science project**.

---

## Project Structure

```bash
.
├── creditcard.csv       # Download this from Kaggle
├── feature_names.json   # Generated by train_model.py
├── fraud_model.pkl      # Trained model
├── scaler.pkl           # Scaler used for preprocessing
├── shap_background.npy  # For SHAP interpretability
├── README.md
├── app.py               # Streamlit web app
├── requirements.txt     # Python dependencies
└── train_model.py       # Model training script
```

---

## How to Run This Project

### 1️⃣ Download the Dataset
1. Go to the Kaggle dataset: [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)  
2. Download the `creditcard.csv` file.  
3. Place it in the same directory as the project files.

---

### 2️⃣ Set Up a Virtual Environment (Recommended)

```bash
# Create a new virtual environment
python -m venv venv

# Activate the environment
# On Windows:
venv\Scripts\activate

# On macOS/Linux:
source venv/bin/activate
```

---

### 3️⃣ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4️⃣ Train the Model (IMPORTANT)

Before running the web app, you must train the model.

```bash
python train_model.py
```

This script will:

- Load `creditcard.csv`
- Preprocess data (`RobustScaler` on `Time` and `Amount`)
- Balance the dataset using **SMOTE**
- Train an **XGBoost Classifier**
- Save all artifacts:
  - `fraud_model.pkl` (model)
  - `scaler.pkl` (scaler)
  - `feature_names.json` (feature names)
  - `shap_background.npy` (sample data for SHAP)

You’ll see a **classification report** in your terminal after training.

---

### 5️⃣ Run the Streamlit Web App

Once training is done, launch the app:

```bash
streamlit run app.py
```

Your browser will automatically open the application dashboard.

---

## SHAP Explainability Dashboard

The **SHAP** feature adds a new tab for model interpretability — essential for trustworthy AI.

When you upload a file, you can:

### Analyze Single Transactions
- Use a slider to select a transaction (from the first 500).  
- View:
  - **Force Plot** → shows which features push the model toward *Fraud* or *Legit*.
  - **Waterfall Plot** → breaks down each feature’s contribution to the final decision.

### Global Feature Importance
- **Summary Bar Plot** → shows average SHAP values per feature.  
- **Beeswarm Plot** → shows distribution and correlation of SHAP values.

This layer of transparency helps you understand *why* the model makes certain predictions.

---

## Requirements

All dependencies are listed in `requirements.txt`.  
If missing packages cause issues, ensure you have these core libraries installed:

```bash
pip install numpy pandas scikit-learn xgboost streamlit shap imbalanced-learn
```

---

## Author
Developed by **Abhinav Harbola**  
Data Science | Machine Learning | Explainable AI
